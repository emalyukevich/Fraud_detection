# ğŸ’³ Credit Card Fraud Detection â€” Advanced ML Project

A project aimed at detecting fraudulent transactions using **unsupervised learning**, **model ensembles**, and **threshold optimization**. The structure and methods are tailored to real-world banking use cases.

---

---

## ğŸ“Œ Project Goals

- ğŸ“‰ Detect fraudulent transactions under extreme class imbalance  
- ğŸ” Leverage **One-Class SVM** for anomaly detection  
- ğŸ§  Build a **model ensemble** to enhance predictions  
- ğŸ›¡ Minimize **False Negatives (FN)** to prevent fraud losses  
- ğŸ§± Implement a **modular architecture** suitable for deployment and scaling

---

## ğŸ—‚ï¸ Project Structure

```bash
project-root/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â””â”€â”€ processed/
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ 01_EDA.ipynb
â”‚ â”œâ”€â”€ 02_Feature_Engineering.ipynb
â”‚ â”œâ”€â”€ 03_Baseline_Classification_Model.ipynb
â”‚ â””â”€â”€ 04_Final_Model_Evaluation.ipynb
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ utils.py
â”‚ â””â”€â”€ models/
â”‚ â”œâ”€â”€ anomaly_detection.ipynb
â”‚ â”œâ”€â”€ ensemble.py
â”‚ â”œâ”€â”€ ensemble_model.joblib
â”‚ â””â”€â”€ oneclasssvm_anomaly_detector.joblib
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

```

---

## ğŸ§  Methods & Tools

| Category                | Techniques and Tools Used                                      |
|------------------------|---------------------------------------------------------------|
| ğŸ“Š Exploratory Analysis | `Boxplot`, Stratified sampling, `UMAP`, Correlation analysis  |
| ğŸ— Feature Engineering  | `StandardScaler`, Feature selection, Feature importance        |
| ğŸ•µ Anomaly Detection    | `One-Class SVM`                                                |
| ğŸ¤– Classification       | `KNN`, `RandomForestClassifier`, `LogisticRegression`          |
| ğŸ” Ensembling           | Averaging probabilities, Threshold optimization               |
| ğŸ“ Evaluation Metrics   | `Recall`, `Precision`, `F1`, `ROC-AUC`, `Confusion Matrix`     |

---

## ğŸ“Š Results

| Metric                   | Value  |
|--------------------------|--------|
| **Recall (Fraud)**       | 0.82   |
| **Precision (Fraud)**    | 0.86   |
| **F1-score (Fraud)**     | 0.84   |
| **ROC AUC (Overall)**    | 0.96   |
| **False Negatives (FN)** | 13     |
| **False Positives (FP)** | 10     |

> ğŸ“Œ The model demonstrates high recall and AUC despite the class imbalance (fraud < 0.2%).

---

## ğŸš€ Quick Start

1. Clone the repository and install dependencies:
```bash
git clone https://github.com/your-username/creditcard-fraud-detection.git
cd creditcard-fraud-detection
pip install -r requirements.txt

2. Preprocess the data:
jupyter notebook notebooks/02_Feature_Engineering.ipynb

3. Train the ensemble:
jupyter notebook notebooks/03_Baseline_Classification_Model.ipynb

4. Evaluate final metrics:
jupyter notebook notebooks/04_Final_Model_Evaluation.ipynb
```
---

## ğŸ”­ Future Enhancements

### ğŸ§  Model and Hyperparameter Tuning

- ğŸ› Implement **fine-tuning of model hyperparameters**:
  - `LogisticRegression`: `penalty`, `C`, `solver`
  - `KNeighborsClassifier`: `n_neighbors`, `weights`, `metric`
  - `RandomForestClassifier`: `n_estimators`, `max_depth`, `class_weight`
- ğŸ§ª Use **GridSearchCV** or `Optuna` for automated parameter optimization

### â± Temporal Pattern Modeling

- ğŸ§© Develop a **time-aware model** that accounts for:
  - Time intervals between transactions (`time_delta` features)
  - Seasonal and daily patterns
  - Rolling statistics (`rolling mean`, `lag features`)
- ğŸ“ˆ Build **customer behavior profiles** over time

### ğŸ“Š Interpretability

- ğŸ§  Integrate **SHAP** for both global and local interpretability
- ğŸ§ª Add **LIME** for instance-specific explanations
- ğŸ’¡ Generate clear reports explaining why a transaction was flagged as fraudulent

### ğŸ›° Deployment and API

- ğŸš€ Build a **FastAPI server** to:
  - Load the trained model
  - Serve predictions via REST API
  - Display metrics and logs via Swagger UI

### ğŸ§® Metrics and Evaluation

- ğŸ“‰ Shift the focus from ROC AUC to **PR AUC (Precision-Recall AUC)**, more suitable for imbalanced data
- âš– Incorporate **cost-sensitive metrics**, such as evaluating the cost of False Negatives (FN) vs False Positives (FP)

### ğŸ· Feature Engineering

- ğŸ§¬ Derive additional features from `One-Class SVM`:
  - `is_anomaly`: binary anomaly flag
  - `decision_function`: continuous anomaly score
  - `rank`: anomaly ranking based on score
- ğŸ”¬ Further enhance features like:
  - `Time`: extract `hour`, `delta_time`, `time_since_last_tx`
  - `Amount`: apply log transformation, scaling, and binning

---